---
title: "MachineLearningProject"
date: '2022-10-24'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Background
 
*Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: <http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har#literature> (see the section on the Weight Lifting Exercise Dataset).*

### I. Load Packages and Download Data

```{r Download Data}
#Load Packages

library(caret)
library(randomForest)
library(rattle)

 
#Download Data
 
training_url <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
testing_url <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
 
training_csv <- read.csv(training_url,na.strings = c("NA",""))
testing_csv <- read.csv(testing_url,na.strings = c("NA",""))

dim(training_csv)

dim(testing_csv)
 
```
### II. Cleaning the Data
 
From analysing the data, it is clear that there is an issue with NAs in certain variables, which should be removed. Additionally, the first 7 variables are descriptive (name, time stamps, date) are not needed. We are left with 53 variables. This a medium sized dataset so the 60% will be allocated to training set and 40% to the testing (i.e. validation) set. 
 
```{r Cleaning Data, echo=TRUE}
#Removing NAs

training_1 <- training_csv[,colSums(is.na(training_csv))==0]
testing_1 <- testing_csv[,colSums(is.na(testing_csv))==0] 
sum(is.na(training_csv))
sum(is.na(training_1))

#Removing Unneeded Variables
 
training_2 <- training_1[,-c(1:7)]
testing_2 <- testing_1[,-c(1:7)]

#Splicing the Data

inTrain <- createDataPartition(y=training_2$classe, p=0.6, list=FALSE)
training <- training_2[inTrain,]
testing <- training_2[-inTrain,]

dim(training)
```

### III. Random Forest

The first model we will try is a Random Forest. Using the validation variable from the splicing, we observe that the cross validation accuracy rate is 99% and out of sample error is less than 1%.

A `trainControl` funciton is used to improve the `caret` models.
 
```{r RandomForest, echo=TRUE}

#Control variable
 
fitControl <- trainControl(method = "cv", number = 5)

#Random Forest Model

modFitRF <- train(classe~., data=training, method="rf", trControl=fitControl, ntree=250)

#Confusion Matrix

predRF <- predict(modFitRF, testing)

cmRF <- confusionMatrix(predRF, factor(testing$classe))
modFitRF
cmRF

 
```

### IV. Decision Tree
 
The second model we will try is a Decision Tree. Here the accuracy has fallen to 49%.

```{r Decision Tree, echo=TRUE}
modFitDT <- train(classe~., data=training, method="rpart", trControl=fitControl)

fancyRpartPlot(modFitDT$finalModel, main="Weight Lifting Exercise Decision Tree", sub="")

predDT <- predict(modFitDT, testing)

cmDT <- confusionMatrix(predDT, factor(testing$classe))
modFitDT
cmDT
 
```

### V. Gradient Boosted Trees/Model (GBM)
 
The final model is a GBM. Here the accuracy improves compared with Decision Tree: 96% accuracy and 4% error.

```{r Boosted Tree, echo=TRUE}
 
modFitGBM <- train(classe~., data=training, method="gbm", trControl=fitControl, verbose=FALSE)

predGBM <- predict(modFitGBM, testing)
cmGBM <- confusionMatrix(predGBM, factor(testing$classe))

modFitGBM
cmGBM

```

### VI. Prediction

Finally, we will use the models to predict 20 different test cases using the original testing data. 
 
The results of the Random Forest and GBM models were the same and were shown to be accurate the Course Project Prediction Quiz. While the results of the Decision Tree were not accurate, which the high out of sample error rate.

 
```{r Prediction, echo=TRUE}

predRF <- predict(modFitRF, testing_csv)
predDT <- predict(modFitDT, testing_csv)
predGBM<- predict(modFitGBM, testing_csv)
 
predRF
predGBM
predDT
```

